{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from sklearn import svm, naive_bayes, neighbors\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import accuracy_score, mean_squared_error, r2_score\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.datasets import load_wine, load_iris, load_boston\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy w/o scaler 0.8148148148148148\n",
      "accuracy with scaler 0.9814814814814815\n"
     ]
    }
   ],
   "source": [
    "features, labels = load_wine(return_X_y=True)\n",
    "features_scaled = StandardScaler().fit(features).transform(features)\n",
    "features_scaled_pca = PCA(n_components=2).fit_transform(features_scaled)\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, labels, test_size=0.3,random_state=42)\n",
    "model_pca = make_pipeline(PCA(n_components=2), naive_bayes.GaussianNB())\n",
    "model_pca.fit(X_train,y_train)\n",
    "prediction = model_pca.predict(X_test)\n",
    "\n",
    "\n",
    "\n",
    "X_train_scaled, X_test_scaled, y_train_scaled, y_test_scaled = train_test_split(features_scaled_pca, labels, test_size=0.3,random_state=42)\n",
    "model_scaled_pca = naive_bayes.GaussianNB()\n",
    "model_scaled_pca.fit(X_train_scaled,y_train_scaled)\n",
    "prediction_scaled = model_scaled_pca.predict(X_test_scaled)\n",
    "\n",
    "print(\"accuracy w/o scaler {0}\".format(metrics.accuracy_score(y_test,prediction)))\n",
    "print(\"accuracy with scaler {0}\".format(metrics.accuracy_score(y_test_scaled,prediction_scaled)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(178, 1)\n"
     ]
    }
   ],
   "source": [
    "x, y = load_wine(return_X_y=True)\n",
    "y=y.reshape(-1,1)\n",
    "print(y.shape)\n",
    "N = len(y)\n",
    "D_in, D_h, D_out =  13, 10, 1\n",
    "\n",
    "w1 = np.random.randn(D_in, D_h)\n",
    "w2 = np.random.randn(D_h, D_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "D_in, H, D_out = 13,100, 1\n",
    "x = np.random.randn(N, D_in)\n",
    "y = np.random.randn(N, D_out)\n",
    "\n",
    "# Randomly initialize weights\n",
    "w1 = np.random.randn(D_in, H)\n",
    "w2 = np.random.randn(H, D_out)\n",
    "\n",
    "learning_rate = 1e-6\n",
    "for t in range(500):\n",
    "\n",
    "  h = x.dot(w1)\n",
    "  h_relu = np.maximum(h, 0)\n",
    "  y_pred = h_relu.dot(w2)\n",
    "  \n",
    "  # Compute and print loss\n",
    "  loss = np.square(y_pred - y).sum()\n",
    "  #rint(t, loss)\n",
    "  \n",
    "  # Backprop to compute gradients of w1 and w2 with respect to loss\n",
    "  grad_y_pred = 2.0 * (y_pred - y)\n",
    "  grad_w2 = h_relu.T.dot(grad_y_pred)\n",
    "  grad_h_relu = grad_y_pred.dot(w2.T)\n",
    "  grad_h = grad_h_relu.copy()\n",
    "  grad_h[h < 0] = 0\n",
    "  grad_w1 = x.T.dot(grad_h)\n",
    " \n",
    "  # Update weights\n",
    "  w1 -= learning_rate * grad_w1\n",
    "  w2 -= learning_rate * grad_w2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "189.740007833\n",
      "[-0.10756527] [-0.14652357]\n",
      "[-0.08243374] [-0.00285049]\n",
      "[ 0.06613395] [-1.16736161]\n",
      "[ 0.05356172] [ 1.2579005]\n",
      "[ 0.06550448] [ 0.84097915]\n",
      "[ 0.23182481] [-0.6300162]\n",
      "[-0.15439449] [ 1.98342365]\n",
      "[ 0.34051247] [-1.55408156]\n",
      "[-0.13015516] [ 0.15525185]\n",
      "[-0.1501388] [-0.54625034]\n"
     ]
    }
   ],
   "source": [
    "lr = 1e-6\n",
    "w1 = np.random.randn(D_in, D_h)\n",
    "w2 = np.random.randn(D_h, D_out)\n",
    "\n",
    "for i in range(0,10000):\n",
    "    h = x.dot(w1)\n",
    "    h_relu = np.maximum(h,0)\n",
    "    y_pred = h_relu.dot(w2)\n",
    "    \n",
    "    error = np.square(y_pred-y).sum()\n",
    "    #print(error)\n",
    "\n",
    "    grad_o = 2.0*(y_pred- y)\n",
    "\n",
    "    grad_w2 = h_relu.T.dot(grad_o)\n",
    "    grad_h_relu = grad_o.dot(w2.T)\n",
    "\n",
    "    grad_h = grad_h_relu.copy()\n",
    "    grad_h[h < 0] = 0\n",
    "    grad_w1 = x.T.dot(grad_h)\n",
    "    w1 -= lr*grad_w1\n",
    "    w2 -= lr*grad_w2\n",
    "print(error)\n",
    "\n",
    "x_test = x[0:10]\n",
    "y_test = y[0:10]\n",
    "\n",
    "h = x_test.dot(w1)\n",
    "h_relu = np.maximum(h,0)\n",
    "y_pred = h_relu.dot(w2)\n",
    "for i in range(len(y_test)):\n",
    "    print(y_pred[i], y_test[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ nan],\n",
       "       [ nan],\n",
       "       [ nan],\n",
       "       [ nan],\n",
       "       [ nan],\n",
       "       [ nan],\n",
       "       [ nan],\n",
       "       [ nan],\n",
       "       [ nan],\n",
       "       [ nan],\n",
       "       [ nan],\n",
       "       [ nan],\n",
       "       [ nan],\n",
       "       [ nan],\n",
       "       [ nan],\n",
       "       [ nan],\n",
       "       [ nan],\n",
       "       [ nan],\n",
       "       [ nan],\n",
       "       [ nan],\n",
       "       [ nan],\n",
       "       [ nan],\n",
       "       [ nan],\n",
       "       [ nan],\n",
       "       [ nan],\n",
       "       [ nan],\n",
       "       [ nan],\n",
       "       [ nan],\n",
       "       [ nan],\n",
       "       [ nan],\n",
       "       [ nan],\n",
       "       [ nan],\n",
       "       [ nan],\n",
       "       [ nan],\n",
       "       [ nan],\n",
       "       [ nan],\n",
       "       [ nan],\n",
       "       [ nan],\n",
       "       [ nan],\n",
       "       [ nan],\n",
       "       [ nan],\n",
       "       [ nan],\n",
       "       [ nan],\n",
       "       [ nan],\n",
       "       [ nan],\n",
       "       [ nan],\n",
       "       [ nan],\n",
       "       [ nan],\n",
       "       [ nan],\n",
       "       [ nan],\n",
       "       [ nan],\n",
       "       [ nan],\n",
       "       [ nan],\n",
       "       [ nan],\n",
       "       [ nan],\n",
       "       [ nan],\n",
       "       [ nan],\n",
       "       [ nan],\n",
       "       [ nan],\n",
       "       [ nan],\n",
       "       [ nan],\n",
       "       [ nan],\n",
       "       [ nan],\n",
       "       [ nan],\n",
       "       [ nan],\n",
       "       [ nan],\n",
       "       [ nan],\n",
       "       [ nan],\n",
       "       [ nan],\n",
       "       [ nan],\n",
       "       [ nan],\n",
       "       [ nan],\n",
       "       [ nan],\n",
       "       [ nan],\n",
       "       [ nan],\n",
       "       [ nan],\n",
       "       [ nan],\n",
       "       [ nan],\n",
       "       [ nan],\n",
       "       [ nan],\n",
       "       [ nan],\n",
       "       [ nan],\n",
       "       [ nan],\n",
       "       [ nan],\n",
       "       [ nan],\n",
       "       [ nan],\n",
       "       [ nan],\n",
       "       [ nan],\n",
       "       [ nan],\n",
       "       [ nan],\n",
       "       [ nan],\n",
       "       [ nan],\n",
       "       [ nan],\n",
       "       [ nan],\n",
       "       [ nan],\n",
       "       [ nan],\n",
       "       [ nan],\n",
       "       [ nan],\n",
       "       [ nan],\n",
       "       [ nan],\n",
       "       [ nan],\n",
       "       [ nan],\n",
       "       [ nan],\n",
       "       [ nan],\n",
       "       [ nan],\n",
       "       [ nan],\n",
       "       [ nan],\n",
       "       [ nan],\n",
       "       [ nan],\n",
       "       [ nan],\n",
       "       [ nan],\n",
       "       [ nan],\n",
       "       [ nan],\n",
       "       [ nan],\n",
       "       [ nan],\n",
       "       [ nan],\n",
       "       [ nan],\n",
       "       [ nan],\n",
       "       [ nan],\n",
       "       [ nan],\n",
       "       [ nan],\n",
       "       [ nan],\n",
       "       [ nan],\n",
       "       [ nan],\n",
       "       [ nan],\n",
       "       [ nan],\n",
       "       [ nan],\n",
       "       [ nan],\n",
       "       [ nan],\n",
       "       [ nan],\n",
       "       [ nan],\n",
       "       [ nan],\n",
       "       [ nan],\n",
       "       [ nan],\n",
       "       [ nan],\n",
       "       [ nan],\n",
       "       [ nan],\n",
       "       [ nan],\n",
       "       [ nan],\n",
       "       [ nan],\n",
       "       [ nan],\n",
       "       [ nan],\n",
       "       [ nan],\n",
       "       [ nan],\n",
       "       [ nan],\n",
       "       [ nan],\n",
       "       [ nan],\n",
       "       [ nan],\n",
       "       [ nan],\n",
       "       [ nan],\n",
       "       [ nan],\n",
       "       [ nan],\n",
       "       [ nan],\n",
       "       [ nan],\n",
       "       [ nan],\n",
       "       [ nan],\n",
       "       [ nan],\n",
       "       [ nan],\n",
       "       [ nan],\n",
       "       [ nan],\n",
       "       [ nan],\n",
       "       [ nan],\n",
       "       [ nan],\n",
       "       [ nan],\n",
       "       [ nan],\n",
       "       [ nan],\n",
       "       [ nan],\n",
       "       [ nan],\n",
       "       [ nan],\n",
       "       [ nan],\n",
       "       [ nan],\n",
       "       [ nan],\n",
       "       [ nan],\n",
       "       [ nan],\n",
       "       [ nan],\n",
       "       [ nan],\n",
       "       [ nan],\n",
       "       [ nan]])"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 315.80740024,    0.        ,    0.        , ...,  258.84526654,\n",
       "           0.        ,  444.84816555],\n",
       "       [ 278.97968875,    0.        ,    0.        , ...,  204.1395723 ,\n",
       "           0.        ,  446.9086231 ],\n",
       "       [ 310.6750569 ,    0.        ,    0.        , ...,  208.58429757,\n",
       "           0.        ,  494.28056739],\n",
       "       ..., \n",
       "       [ 289.39539735,    0.        ,    0.        , ...,  256.00594641,\n",
       "           0.        ,  342.51368581],\n",
       "       [ 288.60395828,    0.        ,    0.        , ...,  252.05800377,\n",
       "           0.        ,  342.56228863],\n",
       "       [ 224.236657  ,    0.        ,    0.        , ...,  210.54718794,\n",
       "           0.        ,  217.94049772]])"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h_relu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  1.32800000e+01   1.64000000e+00   2.84000000e+00   1.55000000e+01\n",
      "   1.10000000e+02   2.60000000e+00   2.68000000e+00   3.40000000e-01\n",
      "   1.36000000e+00   4.60000000e+00   1.09000000e+00   2.78000000e+00\n",
      "   8.80000000e+02]\n"
     ]
    }
   ],
   "source": [
    "class_0 = X_train[y_train==0]\n",
    "class_1 = X_train[y_train==1]\n",
    "class_2 = X_train[y_train==2]\n",
    "\n",
    "class_0_s = X_train_scaled[y_train_scaled==0]\n",
    "class_1_s = X_train_scaled[y_train_scaled==1]\n",
    "class_2_s = X_train_scaled[y_train_scaled==2]\n",
    "\n",
    "print(class_0[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.08452220473 -1.06113799358\n"
     ]
    }
   ],
   "source": [
    "print(class_0[0,0],class_0[0,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(ncols=2, figsize=(10,10))\n",
    "axes[0].scatter(class_0[:,0],class_0[:,1], color='r', marker='o', alpha=0.5)\n",
    "axes[0].scatter(class_1[:,0],class_1[:,1], color='g', marker='^', alpha=0.5)\n",
    "axes[0].scatter(class_2[:,0],class_2[:,1], color='c', marker='s', alpha=0.5)\n",
    "\n",
    "axes[1].scatter(class_0_s[:,0],class_0_s[:,1], color='r', marker='o', alpha=0.5)\n",
    "axes[1].scatter(class_1_s[:,0],class_1_s[:,1], color='g', marker='^', alpha=0.5)\n",
    "axes[1].scatter(class_2_s[:,0],class_2_s[:,1], color='c', marker='s', alpha=0.5)\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy of model_nb: 0.814814814815\n",
      "accuracy of model_nb_scaled: 0.981481481481\n"
     ]
    }
   ],
   "source": [
    "features, labels = load_wine(return_X_y=True)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, labels, test_size=0.3,random_state=42)\n",
    "\n",
    "model_pca = make_pipeline(PCA(n_components=2), naive_bayes.GaussianNB())\n",
    "model_pca.fit(X_train,y_train)\n",
    "prediction = model_pca.predict(X_test)\n",
    "\n",
    "\n",
    "model_scaled_pca = make_pipeline(StandardScaler(), PCA(n_components=2), naive_bayes.GaussianNB())\n",
    "model_scaled_pca.fit(X_train,y_train)\n",
    "prediction_scaled = model_scaled_pca.predict(X_test)\n",
    "\n",
    "\n",
    "accuracy = accuracy_score(y_test,prediction)\n",
    "accuracy_scaled = accuracy_score(y_test,prediction_scaled)\n",
    "\n",
    "\n",
    "accuracy = accuracy_score(y_test, prediction)\n",
    "print('accuracy of model_nb:', accuracy)\n",
    "\n",
    "\n",
    "accuracy_scaled = accuracy_score(y_test,prediction_scaled)\n",
    "print('accuracy of model_nb_scaled:', accuracy_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from sklearn import svm, neighbors, linear_model, naive_bayes\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, r2_score, accuracy_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.datasets import load_iris, load_wine, load_boston"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13\n",
      "accuracy of model_nb: 0.814814814815\n",
      "accuracy of model_nb_scaled: 0.981481481481\n"
     ]
    }
   ],
   "source": [
    "features, labels = load_wine(return_X_y=True)\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, labels, test_size=0.3, random_state=42)\n",
    "\n",
    "model_nb = make_pipeline(PCA(n_components=2), GaussianNB())\n",
    "model_nb.fit(X_train, y_train)\n",
    "prediction =  model_nb.predict(X_test)\n",
    "\n",
    "model_nb_scale = make_pipeline(StandardScaler(), PCA(n_components=2), GaussianNB())\n",
    "model_nb_scale.fit(X_train, y_train)\n",
    "prediction_scaled =  model_nb_scale.predict(X_test)\n",
    "\n",
    "print(len(features[0]))\n",
    "\n",
    "accuracy = accuracy_score(y_test, prediction)\n",
    "print('accuracy of model_nb:', accuracy)\n",
    "\n",
    "\n",
    "accuracy_scaled = accuracy_score(y_test,prediction_scaled)\n",
    "print('accuracy of model_nb_scaled:', accuracy_scaled)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pca = model_nb_scale.named_steps['pca']\n",
    "scaler = model_nb_scale.named_steps['standardscaler']\n",
    "\n",
    "\n",
    "#x_transformed = model_nb_scale.transform(scaler.transform(train_x))\n",
    "X_train_std = pca.transform(scaler.transform(X_train))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_train_std[5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "FIG_SIZE = (10,10)\n",
    "#fig, (ax1, ax2) = plt.subplots(ncols=2, figsize=FIG_SIZE)\n",
    "fig = plt.figure(\"test\", figsize=FIG_SIZE)\n",
    "#(ax1,ax2) = Axes3D(fig,  elev=45, azim=130)\n",
    "#ax = fig.(1,1, projection='3d')\n",
    "ax1 = fig.add_subplot(121, projection='3d')\n",
    "ax2 = fig.add_subplot(122, projection='3d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for l, c, m in zip(range(0, 3), ('blue', 'red', 'green'), ('^', 's', 'o')):\n",
    "    x = X_train[y_train ==l,0]\n",
    "    y = X_train[y_train ==l,1]\n",
    "    z = X_train[y_train ==l,2]\n",
    "    ax1.scatter(x,y,z, color=c, marker=m, alpha=0.5)\n",
    "\n",
    "for l, c, m in zip(range(0, 3), ('blue', 'red', 'green'), ('^', 's', 'o')):\n",
    "    x = X_train_std[y_train ==l,0]\n",
    "    y = X_train_std[y_train ==l,1]\n",
    "    z = X_train_std[y_train ==l,2]\n",
    "    ax2.scatter(x,y,z, color=c, marker=m, alpha=0.5)\n",
    "\n",
    "ax1.set_title(\"Training set after PCA\")    \n",
    "ax2.set_title(\"Training set after PCA with standardizer\")    \n",
    "\n",
    "for a in (ax1,ax2):\n",
    "    a.set_xlabel('pca component 1')\n",
    "    a.set_ylabel('pca component 2')\n",
    "    a.set_zlabel('pca component 3')\n",
    "    a.grid()\n",
    "    \n",
    "\n",
    "plt.show()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "a = np.array([1,2,3,4,5,6,7,8,9])\n",
    "b = np.array([1,0,1,0,1,1,0,0,1])\n",
    "a[b==0]\n",
    "#print(X_train_std[y_train==1,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Automatically created module for IPython interactive environment\n",
      "\n",
      "Prediction accuracy for the normal test dataset with PCA\n",
      "81.48%\n",
      "\n",
      "\n",
      "Prediction accuracy for the standardized test dataset with PCA\n",
      "98.15%\n",
      "\n",
      "\n",
      "PC 1 without scaling:\n",
      " [  1.76342917e-03  -8.35544737e-04   1.54623496e-04  -5.31136096e-03\n",
      "   2.01663336e-02   1.02440667e-03   1.53155502e-03  -1.11663562e-04\n",
      "   6.31071580e-04   2.32645551e-03   1.53606718e-04   7.43176482e-04\n",
      "   9.99775716e-01]\n",
      "\n",
      "PC 1 with scaling:\n",
      " [ 0.13443023 -0.25680248 -0.0113463  -0.23405337  0.15840049  0.39194918\n",
      "  0.41607649 -0.27871336  0.33129255 -0.11383282  0.29726413  0.38054255\n",
      "  0.27507157]\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn import metrics\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import load_wine\n",
    "from sklearn.pipeline import make_pipeline\n",
    "print(__doc__)\n",
    "\n",
    "# Code source: Tyler Lanigan <tylerlanigan@gmail.com>\n",
    "#              Sebastian Raschka <mail@sebastianraschka.com>\n",
    "\n",
    "# License: BSD 3 clause\n",
    "\n",
    "RANDOM_STATE = 42\n",
    "FIG_SIZE = (10, 7)\n",
    "\n",
    "\n",
    "features, target = load_wine(return_X_y=True)\n",
    "\n",
    "# Make a train/test split using 30% test size\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, target,\n",
    "                                                    test_size=0.30,\n",
    "                                                    random_state=RANDOM_STATE)\n",
    "\n",
    "# Fit to data and predict using pipelined GNB and PCA.\n",
    "unscaled_clf = make_pipeline(PCA(n_components=2), GaussianNB())\n",
    "unscaled_clf.fit(X_train, y_train)\n",
    "pred_test = unscaled_clf.predict(X_test)\n",
    "\n",
    "# Fit to data and predict using pipelined scaling, GNB and PCA.\n",
    "std_clf = make_pipeline(StandardScaler(), PCA(n_components=2), GaussianNB())\n",
    "std_clf.fit(X_train, y_train)\n",
    "pred_test_std = std_clf.predict(X_test)\n",
    "\n",
    "# Show prediction accuracies in scaled and unscaled data.\n",
    "print('\\nPrediction accuracy for the normal test dataset with PCA')\n",
    "print('{:.2%}\\n'.format(metrics.accuracy_score(y_test, pred_test)))\n",
    "\n",
    "print('\\nPrediction accuracy for the standardized test dataset with PCA')\n",
    "print('{:.2%}\\n'.format(metrics.accuracy_score(y_test, pred_test_std)))\n",
    "\n",
    "# Extract PCA from pipeline\n",
    "pca = unscaled_clf.named_steps['pca']\n",
    "pca_std = std_clf.named_steps['pca']\n",
    "\n",
    "# Show first principal componenets\n",
    "print('\\nPC 1 without scaling:\\n', pca.components_[0])\n",
    "print('\\nPC 1 with scaling:\\n', pca_std.components_[0])\n",
    "\n",
    "# Scale and use PCA on X_train data for visualization.\n",
    "scaler = std_clf.named_steps['standardscaler']\n",
    "X_train_std = pca_std.transform(scaler.transform(X_train))\n",
    "\n",
    "# visualize standardized vs. untouched dataset with PCA performed\n",
    "fig, (ax1, ax2) = plt.subplots(ncols=2, figsize=FIG_SIZE)\n",
    "\n",
    "\n",
    "for l, c, m in zip(range(0, 3), ('blue', 'red', 'green'), ('^', 's', 'o')):\n",
    "    ax1.scatter(X_train[y_train == l, 0], X_train[y_train == l, 1],\n",
    "                color=c,\n",
    "                label='class %s' % l,\n",
    "                alpha=0.5,\n",
    "                marker=m\n",
    "                )\n",
    "\n",
    "for l, c, m in zip(range(0, 3), ('blue', 'red', 'green'), ('^', 's', 'o')):\n",
    "    ax2.scatter(X_train_std[y_train == l, 0], X_train_std[y_train == l, 1],\n",
    "                color=c,\n",
    "                label='class %s' % l,\n",
    "                alpha=0.5,\n",
    "                marker=m\n",
    "                )\n",
    "\n",
    "ax1.set_title('Training dataset after PCA')\n",
    "ax2.set_title('Standardized training dataset after PCA')\n",
    "\n",
    "for ax in (ax1, ax2):\n",
    "    ax.set_xlabel('1st principal component')\n",
    "    ax.set_ylabel('2nd principal component')\n",
    "    ax.legend(loc='upper right')\n",
    "    ax.grid()\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#df1=pd.get_dummies(df, columns=['Make','Transmission Type'])\n",
    "df = pd.get_dummies(df)\n",
    "data = np.array(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X = data[:-1]\n",
    "y = data[-1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "doors_d = pd.get_dummies(df['Number of Doors'])\n",
    "doors_d.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = {'users':['u1','u2','u3','u4']}\n",
    "df = pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dm = df.Make.astype('category').cat.codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "a = np.random.randn(5,5) < 0.8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ True,  True,  True,  True,  True],\n",
       "       [ True, False,  True,  True,  True],\n",
       "       [ True,  True, False, False,  True],\n",
       "       [ True,  True,  True,  True,  True],\n",
       "       [ True,  True,  True,  True,  True]], dtype=bool)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.95518669,  1.11941106,  0.06289398,  0.4728536 , -0.27957592],\n",
       "       [-1.12739027,  0.10892079, -0.55631356, -0.63589718, -0.27982564],\n",
       "       [ 0.37050857,  0.76235285, -0.75323354,  0.21493627,  0.16727338],\n",
       "       [ 0.55832838,  1.56826117,  0.6105489 , -1.11411829,  0.37140328],\n",
       "       [-1.00438394,  0.53671108, -0.27451828, -1.56283018,  1.74764082]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b = np.random.randn(a.shape[0], a.shape[1])\n",
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "c = np.multiply(a,b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.95518669,  1.11941106,  0.06289398,  0.4728536 , -0.27957592],\n",
       "       [-1.12739027,  0.        , -0.55631356, -0.63589718, -0.27982564],\n",
       "       [ 0.37050857,  0.76235285, -0.        ,  0.        ,  0.16727338],\n",
       "       [ 0.55832838,  1.56826117,  0.6105489 , -1.11411829,  0.37140328],\n",
       "       [-1.00438394,  0.53671108, -0.27451828, -1.56283018,  1.74764082]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x = [(i,k) for i in range(1,3) for k in range(1,3)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(1, 1), (1, 2), (2, 1), (2, 2)]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "a = [i for i in range(1,10) if i > 5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
